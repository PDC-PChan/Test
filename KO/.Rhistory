require('coda')
require('stochvol')
require('tsoutliers')
require('pracma')
require('VGAM')
require('MASS')
require('ExtDist')
require('survival')
require('Hmisc')
require('copula')
require('distr')
require('RQuantLib')
require('bizdays')
require('moments')
require('parallel')
require('foreach')
require('doParallel')
require('xts')
require('rmgarch')
Parent.WD = 'C:/Users/Samuel/Documents/dfkjdf/'
asset.1 = list(symbol = 'MMM',Expiry = as.Date('2017-07-21'),Strike = 180,Right = 'PUT',Premium = 0.496666666666667, Margin = 17196.96, ER = 0.0205259090046548)
asset.2 = list(symbol = 'MCD',Expiry = as.Date('2017-07-21'),Strike = 135,Right = 'PUT',Premium = 0.466666666666667, Margin = 13331.79, ER = 0.0241502948498873)
asset.3 = list(symbol = 'MCD',Expiry = as.Date('2017-07-21'),Strike = 130,Right = 'PUT',Premium = 0.243333333333333, Margin = 10317.46, ER = 0.0176766556502853)
asset.4 = list(symbol = 'TIF',Expiry = as.Date('2017-06-30'),Strike = 74,Right = 'PUT',Premium = 0.183333333333333, Margin = 5835.19, ER = 0.0231979440464047)
asset.5 = list(symbol = 'JNJ',Expiry = as.Date('2017-06-23'),Strike = 114,Right = 'PUT',Premium = 0.146666666666667, Margin = 9399.64, ER = 0.01167134478959)
asset.6 = list(symbol = 'NKE',Expiry = as.Date('2017-06-23'),Strike = 48,Right = 'PUT',Premium = 0.15, Margin = 5016.43, ER = 0.0205763961576348)
asset.7 = list(symbol = 'CME',Expiry = as.Date('2017-06-16'),Strike = 106,Right = 'PUT',Premium = 0.133333333333333, Margin = 8999.26, ER = 0.010805534950557)
asset.8 = list(symbol = 'CME',Expiry = as.Date('2017-06-23'),Strike = 102,Right = 'PUT',Premium = 0.116666666666667, Margin = 7997.69, ER = 0.011149120356149)
asset.9 = list(symbol = 'CME',Expiry = as.Date('2017-06-16'),Strike = 104,Right = 'PUT',Premium = 0.116666666666667, Margin = 8155.73, ER = 0.0108889669111792)
asset.10 = list(symbol = 'KO',Expiry = as.Date('2017-06-30'),Strike = 40,Right = 'PUT',Premium = 0.05, Margin = 3506.47, ER = 0.0105493167759164)
asset.11 = list(symbol = 'KO',Expiry = as.Date('2017-06-23'),Strike = 40.5,Right = 'PUT',Premium = 0.05, Margin = 3899.49, ER = 0.00935804986403096)
asset.12 = list(symbol = 'KO',Expiry = as.Date('2017-06-16'),Strike = 41,Right = 'PUT',Premium = 0.0433333333333333, Margin = 4285.55, ER = 0.00738354832473228)
assets = lapply(1:12,function(x) return(get(paste0('asset.',x))))
SymbolList = unique(sapply(assets,function(x) return(x[['symbol']])))
}
###################################################################
#    Set Parameters
###################################################################
{
BackwardWaveLen  = 0
ForwardWaveLen  = 1
WaveLen = BackwardWaveLen + ForwardWaveLen + 1
}
###################################################################
#    Prepare Data Sets
###################################################################
{
Get.Clean.DatePrice = function(wd) {
####### Read in data  #############
setwd(wd)
Data_Prices = read.csv('Prices.csv', T)
Data_Dates = read.csv('Dates.csv', T)
Prices_Original = Data_Prices$Close
N = length(Prices_Original)
EventType = as.vector(c('Earnings', 'FOMC', 'Xtreme'), mode = 'list')
####### Define Dates and Event Dates #############
Date_Original = as.Date(as.character(Data_Prices$Date), '%m/%d/%Y')
Prices_Original = Prices_Original[order(Date_Original)]
Date_Original = sort(Date_Original)
List_EventDates = lapply(EventType, function(x) {
as.Date(as.character(Data_Dates$Date[Data_Dates$Type == x]), '%m/%d/%Y')
})
names(List_EventDates) = EventType
load_quantlib_calendars('UnitedStates/NYSE',
from = min(Date_Original) - 50,
to = '2021-12-29')
### Trim Date to make sure whole wave exists
WavelengthExistVector = function(stage, EventName)
{
return(sapply(List_EventDates[[EventName]], function(x)
return(
offset(x, stage, 'QuantLib/UnitedStates/NYSE') %in% Date_Original[-1]
)))
}
List_ExistVector = lapply(EventType, function(x) {
1 == apply(cbind(sapply(
seq(-BackwardWaveLen, ForwardWaveLen),
WavelengthExistVector,
x
)), 1, prod)
})
names(List_ExistVector) = EventType
List_EventDates = lapply(EventType, function(x)
List_EventDates[[x]] = List_EventDates[[x]][List_ExistVector[[x]] == T])
names(List_EventDates) = EventType
####### Define Event Indicator #############
CreateIndicator = function(WaveSize, GrandDates, TargetDates)
{
ResultIndicator = rep(F, length(GrandDates))
ResultIndicator[pmax(match(TargetDates, GrandDates) + WaveSize, 1)] = T
return(ResultIndicator)
}
List_EventDatesLogic = lapply(EventType, function(x) {
apply(cbind(
sapply(
seq(-BackwardWaveLen, ForwardWaveLen),
CreateIndicator,
Date_Original,
List_EventDates[[x]]
)
)
, 1, function(y) {
return (T %in% y)
})
})
names(List_EventDatesLogic) = EventType
AllEventsLogic = apply(matrix(unlist(List_EventDatesLogic), ncol = length(EventType)), 1,
function(x) {
return(T %in% x)
})
####### Define Event Stage Identifier #############
List_EventIdentifier = lapply(EventType, function(x) {
return(cbind(
sapply(
seq(-BackwardWaveLen, ForwardWaveLen),
CreateIndicator,
Date_Original,
List_EventDates[[x]]
)
) %*% (1:(WaveLen)))
})
names(List_EventIdentifier) = EventType
##### 1. Return_Original ######
Return_Original = log(Prices_Original[-1] / Prices_Original[-N])
##### 2. Return_ExEvent ######
Return_ExEvent = Return_Original
Mean_ExEvent = mean(Return_ExEvent[AllEventsLogic[-1] == F])
Sd_ExEvent = sd(Return_ExEvent[AllEventsLogic[-1] == F])
Return_ExEvent[AllEventsLogic[-1] == T] = rnorm(length(which(AllEventsLogic[-1] ==
T)), Mean_ExEvent, Sd_ExEvent)
return(list(Date = Date_Original[-1], Return = as.ts(Return_ExEvent)))
}
DatePrices = lapply(paste0(Parent.WD, SymbolList), Get.Clean.DatePrice)
names(DatePrices) = SymbolList
########### Consolidate Date ###########
Date.Raw = unique(unlist(sapply(SymbolList, function(x) {
return(DatePrices[[x]]$Date)
})))
Date.Final = as.Date(Date.Raw[order(Date.Raw)])
########### Consolidate Prices ###########
Return.Final = lapply(lapply(SymbolList, function(x) {
return(DatePrices[[x]]$Return[match(Date.Final, DatePrices[[x]]$Date)])
}), na.locf)
Final.DF = data.frame(matrix(
unlist(Return.Final),
byrow = F,
ncol = length(SymbolList)
))
names(Final.DF) = SymbolList
Final.DF$Date = Date.Final
}
###################################################################
#    Fit Multivate-GARCH Model to ExEvent Returns
###################################################################
{
noise = c('norm',
'snorm',
'std',
'sstd',
'ged',
'sged',
'nig',
'ghyp',
'jsu')
ARMA.Order = c(2, 2)
GetMaxLLSpec = function(symbol) {
Ret_ExEvent = as.ts(Final.DF[symbol])
# Remove all additive outliers
tsoModel = tso(
y = Ret_ExEvent,
types = c('AO'),
tsmethod = 'auto.arima',
args.tsmodel = list(model = 'local-level')
)
# Fit Garch with noise type of Max LL
GarchLL = function(noiseType, inputData)
{
spec = ugarchspec(
mean.model = list(armaOrder = ARMA.Order, include.mean = TRUE),
variance.model = list(model = 'sGARCH'),
distribution.model = noiseType
)
fit = ugarchfit(spec, data = inputData, solver = 'hybrid')
return(likelihood(fit))
}
GarchLL  = sapply(noise, GarchLL, tsoModel$yadj)
maxGarchLLIndex = which(GarchLL == max(GarchLL))
maxGarchSpec = ugarchspec(
mean.model = list(armaOrder = ARMA.Order, include.mean = TRUE),
variance.model = list(model = 'sGARCH'),
distribution.model = noise[maxGarchLLIndex]
)
maxGarchFit = ugarchfit(maxGarchSpec, data = tsoModel$yadj, solver = 'hybrid')
return(list(Fit = maxGarchFit, Spec = maxGarchSpec))
# return( list(Spec =maxGarchSpec ))
}
tso.Remove = function(symbol) {
Ret_ExEvent = as.ts(Final.DF[symbol])
tsoModel = tso(
y = Ret_ExEvent,
types = c('AO'),
tsmethod = 'auto.arima',
args.tsmodel = list(model = 'local-level')
)
return(tsoModel$yadj)
}
Final.DF.oF = data.frame(matrix(
unlist(lapply(SymbolList, tso.Remove)),
byrow = F,
ncol = length(SymbolList)
))
names(Final.DF.oF) = SymbolList
Final.DF.oF$Date = Date.Final
###### Parallel Garch Spec Generation ######
no_cores <<- detectCores() - 1
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, ls(.GlobalEnv))
dummy = clusterEvalQ(cl, library(rugarch))
dummy = clusterEvalQ(cl, library(tsoutliers))
SpecAndFit = parLapply(cl, SymbolList, GetMaxLLSpec)
stopCluster(cl)
FitList = lapply(SpecAndFit, function(x)
return(x$Fit))
SpecList = lapply(SpecAndFit, function(x)
return(x$Spec))
Specs.GARCHs = multispec(SpecList)
###### Fit the mgarch model ######
Specs.DCC = dccspec(
Specs.GARCHs,
VAR = F,
dccOrder = c(1, 1),
model = 'DCC',
distribution = 'mvlaplace'
)
Final.xts = as.xts(Final.DF.oF[, -(1 + length(SymbolList))], order.by =
Final.DF.oF[, length(SymbolList) + 1])
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, ls(.GlobalEnv))
DCC.Model = dccfit(
spec =  Specs.DCC,
data = Final.xts,
solver = c('hybrid', 'solnp'),
cluster = cl
)
stopCluster(cl)
}
###################################################################
#    Generate New Time Series
###################################################################
{
####### Simulation Initialization #############
{
NPaths = 10000
SimulationEndDate = preceding(as.Date("2017-12-31", "%Y-%m-%d"),
'QuantLib/UnitedStates/NYSE')
SimulationStartDate = adjust("UnitedStates/NYSE", max(Final.DF.oF$Date, 1) +
1)
NumOfDays = bizdays(SimulationStartDate,
SimulationEndDate,
'QuantLib/UnitedStates/NYSE') + 1
Date_Future = bizseq(SimulationStartDate,SimulationEndDate,'QuantLib/UnitedStates/NYSE')
}
####### Read in Shock Matricess  #############
{
Read.ShockMatrix = function(futureDates, FilePath){
DataIn = read.csv(FilePath,header = F)
Date.Index = match(futureDates,as.Date(DataIn[,1],'1970-01-01'))
return(as.matrix(DataIn[,-1])[Date.Index,])
}
List.ShockMatrices = lapply(paste0(Parent.WD, SymbolList, '/ShockMatrix.csv'), function(fileAdd) {
return(Read.ShockMatrix(Date_Future, fileAdd))
})
names(List.ShockMatrices) = SymbolList
}
####### Simulate m-GARCH process  #############
mGARCHsim = dccsim(
DCC.Model,
n.sim = NumOfDays,
m.sim = NPaths,
startMethod =  'sample' ,
rseed = 0
)
Simmed.Path = mGARCHsim@msim$simX
Simmed.Path.rbind = do.call("rbind", Simmed.Path)
Simmed.Path.List = lapply((1:length(SymbolList)), function(i) {
return(matrix(Simmed.Path.rbind[, i], byrow = F, ncol = NPaths))
})
names(Simmed.Path.List) = SymbolList
############### combined process with Shocks #############
for(i in (1:length(SymbolList))){
symbol = SymbolList[i]
Simmed.Path.List[[symbol]][List.ShockMatrices[[symbol]][,1]!=0,] = 0
Simmed.Path.List[[symbol]] = Simmed.Path.List[[symbol]] + List.ShockMatrices[[symbol]]
}
}
###################################################################
#       Usefull function for calculation
###################################################################
{
Calculate_Fitted.Expiry.Prices = function(symbol,ExpiryDate)
{
####### Read in data  #############
setwd(paste0(Parent.WD,'/',symbol ))
Data_Prices = read.csv('Prices.csv', T)
LastClose = Data_Prices$Close[as.Date(Data_Prices$Date,'%m/%d/%Y') == max(Final.DF$Date)]
MaturityLength = bizdays(SimulationStartDate, ExpiryDate, 'QuantLib/UnitedStates/NYSE')+1
Fitted.Expiry.Returns = apply(Simmed.Path.List[[symbol]],2,function(x){
prod(exp(head(x,MaturityLength)))
})
return(LastClose*Fitted.Expiry.Returns)
}
payoff = function(ST,K,Premium,Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
return(Premium - max(direction*(K-ST),0))
}
Probability.OTM = function(K,Sim.Prices, Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
return(sum(direction*(Sim.Prices-K) > 0)/NPaths)
}
Cond.Loss = function(K,Sim.Prices, Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
conLoss = mean(direction*(K-Sim.Prices[(direction*(K-Sim.Prices))>0]))
if(is.na(conLoss)) conLoss = 0
return(conLoss)
}
ExReturn = function(K,Sim.Prices,Premium,Right = 'PUT'){
return(mean(sapply(Sim.Prices,payoff,K,Premium,Right)))
}
SDReturn = function(K,Sim.Prices,Premium,Right = 'PUT'){
return(sd(sapply(Sim.Prices,payoff,K,Premium,Right)))
}
}
###################################################################
#       Calculate correlation between assets
###################################################################
{
GetCov = function(asset.A, asset.B) {
assets = list(asset.A, asset.B)
Sim.Prices = lapply(1:2, function(x) {
return(Calculate_Fitted.Expiry.Prices(assets[[x]]$symbol, assets[[x]]$Expiry))
})
Returns = lapply(1:2, function(x) {
return(
sapply(
Sim.Prices[[x]],
payoff,
assets[[x]]$Strike,
assets[[x]]$Premium,
assets[[x]]$Right
) / assets[[x]]$Margin * 780
)
})
return(cov(Returns[[1]],Returns[[2]]))
}
Cov.Matrix = do.call('rbind',lapply(assets,function(x) return(sapply(assets,GetCov,x))))
}
ExcessMargin = 20000
ObjFunction = function(N,assets,CovMatrix){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns - sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
N = rep(1,12)
N
Returns = sapply(assets,function(x) x[['ER']])
Returns
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
CovMatrix = Cov.Matrix
N%*%Mar.Matrix%*%Returns - sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N)
N%*%Mar.Matrix%*%Returns
sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N)
expand.grid(cbind(c(1,2),c(3,4)))
expand.grid(list(a = c(1,2),b = c(3,4)))
Possible.Combo = expand.grid(lapply(1:length(SymbolList),function(x) ExcessMargin%/%assets[[x]]$Margin))
head(Possible.Combo)
Possible.Combo = expand.grid(lapply(1:length(assets),function(x) ExcessMargin%/%assets[[x]]$Margin))
head(Possible.Combo)
Possible.Combo = expand.grid(lapply(1:length(assets),function(x) return(1:ExcessMargin%/%assets[[x]]$Margin)))
lapply(1:length(assets),function(x) return(1:ExcessMargin%/%assets[[x]]$Margin))
x = 1
1:ExcessMargin%/%assets[[x]]$Margin
Possible.Combo = expand.grid(lapply(1:length(assets),function(x) return(1:(ExcessMargin%/%assets[[x]]$Margin))))
lapply(1:length(assets),function(x) return(1:(ExcessMargin%/%assets[[x]]$Margin)))
head(Possible.Combo)
Combos = expand.grid(lapply(1:length(assets),function(x) return(1:(ExcessMargin%/%assets[[x]]$Margin))))
?apply
Possible.OutComes = apply(Combos,1,ObjFunction,assets,Cov.Matrix)[
apply(Combos,1,ReqMargin,assets)<ExcessMargin]
ExcessMargin = 20000
ObjFunction = function(N,assets,CovMatrix){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns - sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
ReqMargin = function(N,assets){
return(N%*%(sapply(assets,function(x) x[['Margin']])))
}
Combos = expand.grid(lapply(1:length(assets),function(x) return(1:(ExcessMargin%/%assets[[x]]$Margin))))
Possible.OutComes = apply(Combos,1,ObjFunction,assets,Cov.Matrix)[
apply(Combos,1,ReqMargin,assets)<ExcessMargin]
Possible.OutComes = apply(Combos,1,ObjFunction,assets,Cov.Matrix)
Possibility =  apply(Combos,1,ReqMargin,assets)<ExcessMargin
max(Possible.OutComes[Possibility])
head(Possibility)
Combos = expand.grid(lapply(1:length(assets),function(x) return(0:(ExcessMargin%/%assets[[x]]$Margin))))
Possible.OutComes = apply(Combos,1,ObjFunction,assets,Cov.Matrix)
Possibility =  apply(Combos,1,ReqMargin,assets)<ExcessMargin
max(Possible.OutComes[Possibility])
str(ls(.GlobalEnv))
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, c('ExcessMargin','ObjFunction','ReqMargin','Combos'))
Possible.OutComes = parApply(cl,Combos,1,ObjFunction,assets,Cov.Matrix)
Possibility =  parApply(cl,Combos,1,ReqMargin,assets)<ExcessMargin
stopCluster(cl)
OutComes = Possible.OutComes
Possible.OutComes = OutComes[Possibility]
Possible.Combos = Combos[Possibility]
Possible.OutComes.Sorted = Possible.OutComes[order(Possible.OutComes,decreasing = T)]
Possible.Combos.Sorted = Possible.Combos[order(Possible.OutComes,decreasing = T)]
head(Possibility)
Possible.OutComes = OutComes[Possibility]
Possible.Combos = Combos[Possibility,]
Possible.OutComes.Sorted = Possible.OutComes[order(Possible.OutComes,decreasing = T)]
Possible.Combos.Sorted = Possible.Combos[order(Possible.OutComes,decreasing = T),]
head(Possible.OutComes.Sorted)
head(Possible.Combos.Sorted)
length(Possible.OutComes.Sorted)
ReqMargin(Possible.Combos.Sorted[1,],assets)
ReqMargin
Possible.Combos.Sorted[1,]
ReqMargin(Possible.Combos.Sorted[1,],assets = assets)
sapply(assets,function(x) x[['Margin']])
Possible.Combos.Sorted[1,]%*%sapply(assets,function(x) x[['Margin']])
ReqMargin(as.numeric(Possible.Combos.Sorted[1,]),assets = assets)
Return.Function = function(N,assets){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns)
}
SD.Function = function(N,assets,CovMatrix){
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
Possible.Return.Sorted = apply(Possible.Combos.Sorted,1,Return.Function,assets)
Possible.SD.Sorted = apply(Possible.Combos.Sorted,1,SD.Function,assets,Cov.Matrix)
Possible.OutComes.Sorted[1]
Possible.Return.Sorted[1]
Possible.SD.Sorted[1]
354.7335/20000
ExcessMargin = 20000
ObjFunction = function(N,assets,CovMatrix){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns/sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
Return.Function = function(N,assets){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns)
}
SD.Function = function(N,assets,CovMatrix){
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
ReqMargin = function(N,assets){
return(N%*%(sapply(assets,function(x) x[['Margin']])))
}
Combos = expand.grid(lapply(1:length(assets),function(x) return(0:(ExcessMargin%/%assets[[x]]$Margin))))
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, c('ExcessMargin','ObjFunction','ReqMargin','Combos'))
OutComes = parApply(cl,Combos,1,ObjFunction,assets,Cov.Matrix)
Possibility =  parApply(cl,Combos,1,ReqMargin,assets)<ExcessMargin
stopCluster(cl)
Possible.OutComes = OutComes[Possibility]
Possible.Combos = Combos[Possibility,]
Possible.OutComes.Sorted = Possible.OutComes[order(Possible.OutComes,decreasing = T)]
Possible.Combos.Sorted = Possible.Combos[order(Possible.OutComes,decreasing = T),]
Possible.Return.Sorted = apply(Possible.Combos.Sorted,1,Return.Function,assets)
Possible.SD.Sorted = apply(Possible.Combos.Sorted,1,SD.Function,assets,Cov.Matrix)
Possible.OutComes.Sorted[1]
Possible.Return.Sorted[1]
Possible.SD.Sorted[1]
ExcessMargin = 140000
ObjFunction = function(N,assets,CovMatrix){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns/sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
Return.Function = function(N,assets){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns)
}
SD.Function = function(N,assets,CovMatrix){
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
ReqMargin = function(N,assets){
return(N%*%(sapply(assets,function(x) x[['Margin']])))
}
Combos = expand.grid(lapply(1:length(assets),function(x) return(0:(ExcessMargin%/%assets[[x]]$Margin))))
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, c('ExcessMargin','ObjFunction','ReqMargin','Combos'))
OutComes = parApply(cl,Combos,1,ObjFunction,assets,Cov.Matrix)
Possibility =  parApply(cl,Combos,1,ReqMargin,assets)<ExcessMargin
stopCluster(cl)
Possible.OutComes = OutComes[Possibility]
Possible.Combos = Combos[Possibility,]
Possible.OutComes.Sorted = Possible.OutComes[order(Possible.OutComes,decreasing = T)]
Possible.Combos.Sorted = Possible.Combos[order(Possible.OutComes,decreasing = T),]
Possible.Return.Sorted = apply(Possible.Combos.Sorted,1,Return.Function,assets)
Possible.SD.Sorted = apply(Possible.Combos.Sorted,1,SD.Function,assets,Cov.Matrix)
