q.initial = 13.324388
sigma.inital = 27.2256663
a0.Fitted = c(1.12,.03,.57)
p0.Fitted = matrix(c(.203,.297,.308,.297,.579,.852,.308,.852,1.63),nrow = 3,byrow = T)
# optimize the Total Log likelihood function
firstGuess = c(h = h.initial,q = q.initial, sigma = sigma.inital)
fit = optim(firstGuess,TotalLLFunctions, NULL, step, mySeries)
lastFitPar = fit$par
# re-optimize until converge
for(i in 1:round(step/10,0))
{
fit = optim(lastFitPar, TotalLLFunctions,NULL, step, mySeries)
if (all(fit$par == lastFitPar)) {
break
}else
{
lastFitPar = fit$par
}
}
# predict the next element
targetSet = seq(1,length(mySeries),by = step)
ts.target = rev(rev(mySeries)[targetSet])
Theta.Fitted = fit$par
sp.Fitted <- KCAss(Theta.Fitted["h"], Theta.Fitted["q"], Theta.Fitted["sigma"],a0.Fitted,p0.Fitted)
FKF.Fitted <- fkf(a0 = sp.Fitted$a0, P0 = sp.Fitted$P0, dt = sp.Fitted$dt, ct = sp.Fitted$ct,
Tt = sp.Fitted$Tt,Zt = sp.Fitted$Zt, HHt = sp.Fitted$HHt, GGt = sp.Fitted$GGt,
yt = matrix(ts.target,nrow=1))
FKF.att = FKF.Fitted$att
# Set up return object
returnObj$theta = fit$par
returnObj$sp = sp.Fitted
returnObj$FKF = FKF.Fitted
returnObj$Prediction = (sp.Fitted$Tt %*% FKF.att[,ncol(FKF.att)])[1,1]
return (returnObj)
}
}
################################################################################################
## Augmented N Step Prediction Function
################################################################################################
{
AugmentedNStep = function(mySeries, step, degree)
{
N = length(mySeries)
return (mean(sapply(0:degree, function(i) (SolidNStep(head(mySeries,(N-i)),step+i))$Prediction)))
}
}
KCA.Backtest = function(mySeries, myRange, step, method = "Solid", degree = 10)
{
## Create empty return object
returnObj = list()
## Insert original time series
returnObj$Original = mySeries[myRange]
## Insert prediction
if (method == "Solid") {
returnObj$Prediction = sapply(myRange, function(x) SolidNStep(head(mySeries,x-step),step)$Prediction)
}else
{
returnObj$Prediction = sapply(myRange, function(x) AugmentedNStep(head(mySeries,x-step),step,degree))
}
## Insert error time series
returnObj$Error = returnObj$Original - returnObj$Prediction
## Calculate Variance
returnObj$TotalVariance = var(returnObj$Error)
return(returnObj)
}
################################################################################################
## Read and clean series
################################################################################################
data = read.table("C:/Users/Samuel/Downloads/test.txt",header = F,sep = ",")
N = nrow(data)
################################################################################################
## Detect abnormality
################################################################################################
## Detect Zeros
LargerThanZero = as.logical((data$V3>0)*(data$V4>0))
data = data[LargerThanZero,]
N = nrow(data)
## Detect outliers
bidReturn = log(data$V3[2:N]) - log(data$V3[1:(N-1)])
askReturn = log(data$V4[2:N]) - log(data$V4[1:(N-1)])
abnormReturnTH = .001
StayVector = c(T,as.logical(sapply(bidReturn, function(x) return(x< abnormReturnTH && x>(-abnormReturnTH)))
* sapply(askReturn, function(x) return(x<abnormReturnTH && x>(-abnormReturnTH)))))
data = data[StayVector,]
N = nrow(data)
################################################################################################
## Last mini-second vector
################################################################################################
mySeries = (data$V3+data$V4)/2
V1 = data$V1
TimeSeries = unique(V1)
names(TimeSeries) = "V1"
myDT = data.frame(V1,mySeries)
DTmy = myDT[N:1,]
mySeries = DTmy[match(TimeSeries,DTmy[,1]),2]
################################################################################################
## Construct Loess
################################################################################################
n = length(mySeries)
myLoessSeries = LastLoessFunction(mySeries,2000)
my_LoessSeries = myLoessSeries[4500:n]
aaa = SolidNStep(my_LoessSeries[1:10000],600)
names(aaa)
aaa$Prediction
aa = SolidNStep(my_LoessSeries[1:10000],60)
aa
names(aa)
aa$Prediction
my_LoessSeries[10060]
aa = SolidNStep(my_LoessSeries[1:10540],60)
aa$Prediction
my_LoessSeries[10600]
aa = SolidNStep(my_LoessSeries[1:10540],100)
aa$Prediction
my_LoessSeries[10640]
aa = SolidNStep(my_LoessSeries[1:10540],500)
aa = SolidNStep(my_LoessSeries[1:10540],300)
my_LoessSeries[10840]
aa$Prediction
plot(my_LoessSeries[10540:10840], type = "l")
plot(my_LoessSeries[10540:10840], type = "l")
my_Series = mySeries[4500:n]
my_Mat = cbind(my_Series,my_LoessSeries)
plot(my_Mat[10540:10840,], type = "l")
matplot(my_Mat[10540:10840,], type = "l")
x = 10000
step = 300
aaa = SolidNStep(my_LoessSeries[1:x],step)
matplot(my_Mat[x:(x+step),],type = "l")
my_LoessSeries[x+step]
aaa$Prediction
x = 10000
step = 100
aaa = SolidNStep(my_LoessSeries[1:x],step)
matplot(my_Mat[x:(x+step),],type = "l")
my_LoessSeries[x+step]
aaa$Prediction
x = 11000
step = 100
aaa = SolidNStep(my_LoessSeries[1:x],step)
matplot(my_Mat[x:(x+step),],type = "l")
my_LoessSeries[x+step]
aaa$Prediction
x = 9000
step = 100
aaa = SolidNStep(my_LoessSeries[1:x],step)
matplot(my_Mat[x:(x+step),],type = "l")
my_LoessSeries[x+step]
aaa$Prediction
x = 11000
step = 100
aaa = SolidNStep(my_LoessSeries[1:x],step)
matplot(my_Mat[x:(x+step),],type = "l")
my_LoessSeries[x+step]
aaa$Prediction
x = 11000
step = 100
aaa = AugmentedNStep(my_LoessSeries[1:x],step,5)
matplot(my_Mat[x:(x+step),],type = "l")
my_LoessSeries[x+step]
aaa
x = 11000
step = 100
aaa = SolidNStep(my_LoessSeries[1:x],step)
matplot(my_Mat[(x-100):(x+step),],type = "l")
my_LoessSeries[x]
my_LoessSeries[x+step]
aaa$Prediction
theData = cbind(1:100,2:101,3:102,4:103]
theData = cbind(1:100,2:101,3:102,4:103)
EventIndCol = c(2,3,4)
ExEventRet = theData[,-EventCol]
ExEventRet = theData[,-EventIndCol]
ExEventRet
1_Earnings= 1:100
Earnings_1= 1:100
1=T
1==T
0=T
0==T
0==F
apply?
?apply
?lapply
?apply
a = c(1,2)
b = c(1,1,2,2)
match(a,b)
aa = as.Date("2017-03-19","%Y-%m-%d")
aa
as.numeric(aa)
FilePath = 'C:/Users/Samuel/Documents/Book1.csv'
DataIn = read.csv(FilePath,header = F)
ShockMatrix.Raw = as.matrix(DataIn[,-1])
ShockMatrix.Raw
as.Date(DataIn[,1])
as.Date(DataIn[,1],'1970-1-1')
?as.Date
install.packages("libsvm")
load("C:/Users/Samuel/Downloads/.RData")
rm(list=ls())
Right = 'Put'
direction = 2*(Right == 'Put')-1
direction
source('~/Visual Studio 2013/Projects/ConsoleApplication5/R Codes/R_RequireFiles.R')
asset.1 = list(symbol = 'ORCL', Expiry = as.Date('2017-07-14'), Strike = 38.5,Right = 'PUT')
asset.2 = list(symbol = 'NKE', Expiry = as.Date('2017-06-23'), Strike = 48,Right = 'PUT')
asset.3 = list(symbol = 'TIF', Expiry = as.Date('2017-06-30'), Strike = 74,Right = 'PUT')
asset.4 = list(symbol = 'JNJ', Expiry = as.Date('2017-07-21'), Strike = 105,Right = 'PUT')
asset.5 = list(symbol = 'MMM', Expiry = as.Date('2017-07-21'), Strike = 165,Right = 'PUT')
asset.6 = list(symbol = 'MMM', Expiry = as.Date('2017-07-21'), Strike = 180,Right = 'PUT')
asset.7 = list(symbol = 'MCD', Expiry = as.Date('2017-07-21'), Strike = 130,Right = 'PUT')
asset.8 = list(symbol = 'TIF', Expiry = as.Date('2017-06-30'), Strike = 75,Right = 'PUT')
asset.9 = list(symbol = 'MMM', Expiry = as.Date('2017-06-30'), Strike = 175,Right = 'PUT')
asset.10 = list(symbol = 'MCD', Expiry = as.Date('2017-07-21'), Strike = 135,Right = 'PUT')
asset.11 = list(symbol = 'MCD', Expiry = as.Date('2017-08-18'), Strike = 130,Right = 'PUT')
asset.12 = list(symbol = 'DIS', Expiry = as.Date('2017-06-30'), Strike = 96,Right = 'PUT')
asset.13 = list(symbol = 'MCD', Expiry = as.Date('2017-08-18'), Strike = 135,Right = 'PUT')
asset.14 = list(symbol = 'T', Expiry = as.Date('2017-06-23'), Strike = 34.5,Right = 'PUT')
asset.15 = list(symbol = 'CPB', Expiry = as.Date('2017-07-21'), Strike = 52.5,Right = 'PUT')
asset.16 = list(symbol = 'DIS', Expiry = as.Date('2017-06-30'), Strike = 97.5,Right = 'PUT')
assets = lapply(1:16,function(x) return (get(paste0('asset.', x))))
216800
###################################################################
#    Prepare Libraries
###################################################################
{
# install.packages('Rcpp')
# install.packages('multicool')
# install.packages('rugarch')
# install.packages('coda')
# install.packages('stochvol')
# install.packages('shiny')
# install.packages('tsoutliers')
# install.packages('pracma')
# install.packages('VGAM')
# install.packages('MASS')
# install.packages('ExtDist')
# install.packages('survival')
# install.packages('Hmisc')
# install.packages('copula')
# install.packages('distr')
# {
#  install.packages('drat')
#  drat::addRepo('ghrr')
#  install.packages('RQuantLib', type='binary')
# }
# install.packages('bizdays')
#
# install.packages('moments')
# install.packages('snow')
# install.packages('parallel')
# install.packages('foreach')
# install.packages('doParallel')
# install.packages('xts')
# install.packages('rmgarch')
require('Rcpp')
require('shiny')
require('parallel')
require('multicool')
require('rugarch')
require('reshape2')
require('coda')
require('stochvol')
require('tsoutliers')
require('pracma')
require('VGAM')
require('MASS')
require('ExtDist')
require('survival')
require('Hmisc')
require('copula')
require('distr')
require('RQuantLib')
require('bizdays')
require('moments')
require('parallel')
require('foreach')
require('doParallel')
require('xts')
require('rmgarch')
require('DEoptim')
require('plyr')
Parent.WD = 'C:/Users/Samuel/Documents/dfkjdf/'
asset.1 = list(symbol = 'AMZN')
asset.2 = list(symbol = 'M')
assets = lapply(1:2,function(x) return (get(paste0('asset.', x))))
SymbolList = sapply(1:2,function(x) return(assets[[x]][['symbol']]))
load_quantlib_calendars('UnitedStates/NYSE', from='2009-01-01', to='2019-12-31')
}
###################################################################
#    Prepare Data Sets
###################################################################
{
Get.Clean.DatePrice = function(wd) {
####### Read in data  #############
setwd(wd)
Data_Prices = read.csv('Prices.csv', T)
Prices_Original = Data_Prices$Close
Date_Original = as.Date(Data_Prices$Date,'%Y-%m-%d')
N = length(Prices_Original)
Return_Original = log(Prices_Original[-1] / Prices_Original[-N])
return(list(Date = Date_Original[-1], Return = as.ts(Return_Original)))
}
DatePrices = lapply(paste0(Parent.WD, SymbolList), Get.Clean.DatePrice)
names(DatePrices) = SymbolList
########### Consolidate Date ###########
Date.Raw = unique(as.numeric(unlist(sapply(SymbolList, function(x) {
return(DatePrices[[x]]$Date)
}))))
Date.Final = as.Date(Date.Raw[order(Date.Raw)])
########### Consolidate Prices ###########
Return.Final = lapply(lapply(SymbolList, function(x) {
return(DatePrices[[x]]$Return[match(Date.Final, DatePrices[[x]]$Date)])
}), na.locf)
Final.DF = data.frame(matrix(
unlist(Return.Final),
byrow = F,
ncol = length(SymbolList)
))
names(Final.DF) = SymbolList
Final.DF$Date = Date.Final
}
###################################################################
#    Fit Multivate-GARCH Model to ExEvent Returns
###################################################################
{
noise = c('norm',
'snorm',
'std',
'sstd',
'ged',
'sged',
'nig',
'ghyp',
'jsu')
ARMA.Order = c(2, 2)
GetMaxLLSpec = function(symbol) {
Ret_ExEvent = as.ts(Final.DF[symbol])
# Fit Garch with noise type of Max LL
GarchLL = function(noiseType, inputData)
{
spec = ugarchspec(
mean.model = list(armaOrder = ARMA.Order, include.mean = TRUE),
variance.model = list(model = 'gjrGARCH'),
distribution.model = noiseType
)
fit = ugarchfit(spec, data = inputData, solver = 'hybrid')
return(likelihood(fit))
}
GarchLLs  = sapply(noise, GarchLL, Ret_ExEvent)
maxGarchLLIndex = which(GarchLLs == max(GarchLLs))
maxGarchSpec = ugarchspec(
mean.model = list(armaOrder = ARMA.Order, include.mean = TRUE),
variance.model = list(model = 'gjrGARCH'),
distribution.model = noise[maxGarchLLIndex]
)
maxGarchFit = ugarchfit(maxGarchSpec, data = Ret_ExEvent, solver = 'hybrid')
return(list(Fit = maxGarchFit, Spec = maxGarchSpec))
# return( list(Spec =maxGarchSpec ))
}
###### Parallel Garch Spec Generation ######
no_cores <<- detectCores() - 1
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, ls(.GlobalEnv))
dummy = clusterEvalQ(cl, library(rugarch))
SpecAndFit = parLapply(cl, SymbolList, GetMaxLLSpec)
stopCluster(cl)
FitList = lapply(SpecAndFit, function(x)
return(x$Fit))
SpecList = lapply(SpecAndFit, function(x)
return(x$Spec))
# Specs.GARCHs = multispec(SpecList)
Specs.GARCHs = multispec(SpecList)
###### Fit the mgarch model ######
Specs.DCC = dccspec(
Specs.GARCHs,
VAR = F,
dccOrder = c(1, 1),
model = 'DCC',
distribution = 'mvlaplace'
)
Final.xts = as.xts(Final.DF[, -(1 + length(SymbolList))], order.by =
Final.DF[, length(SymbolList) + 1])
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, ls(.GlobalEnv))
DCC.Model = dccfit(
spec =  Specs.DCC,
data = Final.xts,
solver = c('hybrid', 'solnp'),
cluster = cl
)
stopCluster(cl)
}
####### Simulation Initialization #############
{
NPaths = 10000
SimulationEndDate = preceding(as.Date("2017-12-31", "%Y-%m-%d"),
'QuantLib/UnitedStates/NYSE')
SimulationStartDate = adjust("UnitedStates/NYSE", max(Final.DF$Date, 1) + 1)
NumOfDays = bizdays(SimulationStartDate,
SimulationEndDate,
'QuantLib/UnitedStates/NYSE') + 1
Date_Future = bizseq(SimulationStartDate,SimulationEndDate,'QuantLib/UnitedStates/NYSE')
}
####### Simulate m-GARCH process  #############
mGARCHsim = dccsim(
DCC.Model,
n.sim = NumOfDays,
m.sim = NPaths,
startMethod =  'sample' ,
rseed = 0
)
Simmed.Path = mGARCHsim@msim$simX
Simmed.Path.rbind = do.call("rbind", Simmed.Path)
Simmed.Path.List = lapply((1:(length(SymbolList))), function(i) {
return(matrix(Simmed.Path.rbind[, i], byrow = F, ncol = NPaths))
})
names(Simmed.Path.List) = SymbolList
############### SELECTED PRICE PLOTS #############
Simmed.Price.List = lapply(SymbolList, function(symbol){
setwd(paste0(Parent.WD,'/',symbol ))
Data_Prices = read.csv('Prices.csv', T)
LastClose = Data_Prices$Close[as.Date(Data_Prices$Date,'%Y-%m-%d') == max(Final.DF$Date)]
return(apply(Simmed.Path.List[[symbol]],2,function(r){return(LastClose*cumprod((1+r)))}))
})
names(Simmed.Price.List) = SymbolList
####### Simulation Initialization #############
{
NPaths = 10000
SimulationEndDate = preceding(as.Date("2017-12-15", "%Y-%m-%d"),
'QuantLib/UnitedStates/NYSE')
SimulationStartDate = adjust("UnitedStates/NYSE", max(Final.DF$Date, 1) + 1)
NumOfDays = bizdays(SimulationStartDate,
SimulationEndDate,
'QuantLib/UnitedStates/NYSE') + 1
Date_Future = bizseq(SimulationStartDate,SimulationEndDate,'QuantLib/UnitedStates/NYSE')
}
####### Simulate m-GARCH process  #############
mGARCHsim = dccsim(
DCC.Model,
n.sim = NumOfDays,
m.sim = NPaths,
startMethod =  'sample' ,
rseed = 0
)
Simmed.Path = mGARCHsim@msim$simX
Simmed.Path.rbind = do.call("rbind", Simmed.Path)
Simmed.Path.List = lapply((1:(length(SymbolList))), function(i) {
return(matrix(Simmed.Path.rbind[, i], byrow = F, ncol = NPaths))
})
names(Simmed.Path.List) = SymbolList
############### SELECTED PRICE PLOTS #############
Simmed.Price.List = lapply(SymbolList, function(symbol){
setwd(paste0(Parent.WD,'/',symbol ))
Data_Prices = read.csv('Prices.csv', T)
LastClose = Data_Prices$Close[as.Date(Data_Prices$Date,'%Y-%m-%d') == max(Final.DF$Date)]
return(apply(Simmed.Path.List[[symbol]],2,function(r){return(LastClose*cumprod((1+r)))}))
})
names(Simmed.Price.List) = SymbolList
####### Simulation Initialization #############
{
NPaths = 10000
SimulationEndDate = preceding(as.Date("2017-12-15", "%Y-%m-%d"),
'QuantLib/UnitedStates/NYSE')
SimulationStartDate = adjust("UnitedStates/NYSE", max(Final.DF$Date, 1) + 1)
NumOfDays = bizdays(SimulationStartDate,
SimulationEndDate,
'QuantLib/UnitedStates/NYSE') + 1
Date_Future = bizseq(SimulationStartDate,SimulationEndDate,'QuantLib/UnitedStates/NYSE')
}
9590+3204
Sharpe.Ratio = function(x){
Portfolio = c(x,-100)
Portfolio.Paths = matrix(matrix(unlist(Simmed.Price.List),byrow = F,ncol = 2) %*% Portfolio,
byrow = F,ncol = NPaths)
Portfolio.Returns = Portfolio.Paths[nrow(Portfolio.Paths),]-Portfolio.Paths[1,]
summary(Portfolio.Returns)
return(mean(Portfolio.Returns)/sd(Portfolio.Returns)  )
}
Sharpe.Ratio(5)
Sharpe.Ratio(6)
Sharpe.Ratio = function(x){
Portfolio = c(x,-100)
Portfolio.Paths = matrix(matrix(unlist(Simmed.Price.List),byrow = F,ncol = 2) %*% Portfolio,
byrow = F,ncol = NPaths)
Portfolio.Returns = Portfolio.Paths[nrow(Portfolio.Paths),]-Portfolio.Paths[1,]
print(summary(Portfolio.Returns))
return(mean(Portfolio.Returns)/sd(Portfolio.Returns))
}
Sharpe.Ratio(6)
Sharpe.Ratio = function(x){
Portfolio = c(x,-100)
Portfolio.Paths = matrix(matrix(unlist(Simmed.Price.List),byrow = F,ncol = 2) %*% Portfolio,
byrow = F,ncol = NPaths)
Portfolio.Returns = Portfolio.Paths[nrow(Portfolio.Paths),]-Portfolio.Paths[1,]
print(summary(Portfolio.Returns)/(x*1919+3204))
return(mean(Portfolio.Returns)/sd(Portfolio.Returns))
}
sapply(1:10,Sharpe.Ratio)
sapply(1:20,Sharpe.Ratio)
25*1919+3204
Sharpe.Ratio(7)
Sharpe.Ratio = function(x){
Portfolio = c(x,-100)
Portfolio.Paths = matrix(matrix(unlist(Simmed.Price.List),byrow = F,ncol = 2) %*% Portfolio,
byrow = F,ncol = NPaths)
Portfolio.Returns = Portfolio.Paths[nrow(Portfolio.Paths),]-Portfolio.Paths[1,]
print(summary(Portfolio.Returns)) #/(x*1919+3204)
return(mean(Portfolio.Returns)/sd(Portfolio.Returns))
}
Sharpe.Ratio(7)
