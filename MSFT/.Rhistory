Return_ExEvent[AllEventsLogic[-1] == T] = rnorm(length(which(AllEventsLogic[-1]==T)),Mean_ExEvent,Sd_ExEvent)
##### 3. Return_Original_Detrend ######
Return_Original_DT = detrend(Return_Original)
##### 4. Return_ExEvent_Detrend ######
Return_ExEvent_DT = Return_Original_DT
Mean_ExEvent_DT =mean(Return_ExEvent_DT[AllEventsLogic[-1] == F])
Sd_ExEvent_DT =sd(Return_ExEvent_DT[AllEventsLogic[-1] == F])
Return_ExEvent_DT[AllEventsLogic[-1] == T] = rnorm(length(which(AllEventsLogic[-1]==T)),Mean_ExEvent_DT,Sd_ExEvent_DT)
}
###################################################################
#    Fit Model to ExEvent Returns
###################################################################
{
Ret_ExEvent = as.ts(Return_ExEvent)
# Remove all additive outliers
tsoModel = tso(y = Ret_ExEvent,types = c("AO"),tsmethod = "auto.arima", args.tsmodel = list(model = "local-level"))
# Fit Garch with noise type of Max LL
noise = c("norm", "snorm", "std","sstd","ged","sged","nig","ghyp","jsu")
ARMA.Order = c(2,2)
GarchLL = function(noiseType, inputData)
{
spec = ugarchspec(mean.model = list(armaOrder = ARMA.Order, include.mean = TRUE),variance.model = list(model = "sGARCH"), distribution.model = noiseType)
fit = ugarchfit(spec, data = inputData, solver = "hybrid")
return(likelihood(fit))
}
GarchLL  = sapply(noise,GarchLL,tsoModel$yadj)
maxGarchLLIndex = which(GarchLL == max(GarchLL))
maxGarchSpec = ugarchspec(mean.model = list(armaOrder = ARMA.Order, include.mean = TRUE),variance.model = list(model = "sGARCH"), distribution.model =noise[maxGarchLLIndex])
maxGarchFit = ugarchfit(maxGarchSpec, data = tsoModel$yadj,solver = "hybrid")
# Fit stochastic Volatility Model
#dataDM = svsample(tsoModel$yadj)
#summary(dataDM,showlatent = F)
}
###################################################################
#    Fit Model to Event Returns
###################################################################
{
####### Prepare data to be fitted ###########
{
EventType_ToFit = EventType[-3]
dataTreatmentFunc = function(x) x^2
GetEventShocks = function(Identifier,Event)
{
return(Return_Original[List_EventIdentifier[[Event]][-1]==Identifier])
}
GetEventSeries = function(Event)
{
return(lapply((1:(WaveLen)),GetEventShocks,Event))
}
List_EventByIdentifier.Raw = lapply(EventType_ToFit,GetEventSeries)
names(List_EventByIdentifier.Raw) = EventType_ToFit
List_EventByIdentifier = lapply(EventType_ToFit,function(x){
nonZeroCol = (apply(matrix(unlist(List_EventByIdentifier.Raw[[x]]),ncol  = WaveLen),1,prod)!=0)
return(lapply(1:WaveLen,function(i){
return(List_EventByIdentifier.Raw[[x]][[i]][nonZeroCol])}))})
names(List_EventByIdentifier) = EventType_ToFit
}
####### Estimate distributions #####
{
####### Estimate Gamma distribution parameters by MLE #####
{
List_GammaObj = lapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(fitdistr(y, "gamma"))
})
})
names(List_GammaObj) = EventType_ToFit
gamma_ML = t(sapply(EventType_ToFit,function(x){
return(lapply(List_GammaObj[[x]],function(y) return(y$loglik)))
}))
}
####### Estimate Levy distribution parameters by MLE #####
{
List_LevyObj = lapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(vglm(y~1,levy(location = 0),maxit = 500))
})
})
names(List_LevyObj) = EventType_ToFit
Levy_ML = t(sapply(EventType_ToFit,function(x){
return(lapply(List_LevyObj[[x]],function(y) return(logLik.vlm(y))))
}))
}
####### Estimate Weibull distribution parameters by MLE #####
{
List_WeibullObj = lapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(eWeibull(y))
})
})
names(List_WeibullObj) = EventType_ToFit
Weibull_ML = t(sapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(lWeibull(y,param = eWeibull(y)))
})
}))
}
####### Estimate Beta distribution parameters by MLE #####
{
List_BetaObj = lapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(eBeta(y))
})
})
names(List_BetaObj) = EventType_ToFit
Beta_LL = t(sapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(lBeta(y,param = eBeta(y)))
})
}))
}
####### Estimate Laplace distribution parameters by MLE #####
{
List_LaplaceObj = lapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(eLaplace(y))
})
})
names(List_LaplaceObj) = EventType_ToFit
Laplace_ML = t(sapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(lLaplace(y,param = eLaplace(y)))
})
}))
}
####### Estimate Uniform distribution parameters by MLE #####
{
List_UniformObj = lapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(eUniform(y))
})
})
names(List_UniformObj) = EventType_ToFit
Uniform_ML = t(sapply(EventType_ToFit,function(x){
lapply(lapply(List_EventByIdentifier[[x]],dataTreatmentFunc),function(y){
return(lUniform(y,param = eUniform(y)))
})
}))
}
}
####### Overlay Gamma distribution curve with data ########
{
overlayEventChart = function(EventName,day)
{
###### Prepare Data ######
d_plot = dataTreatmentFunc((List_EventByIdentifier[[EventName]][[day]]))
EventIndex = which(EventType == EventName)
DayIndex = day
###### Plot Data ######
hist(d_plot,breaks = 10, freq = F, xlab = "",
main = paste(EventName,"(Day",day,")"))
curve(dgamma(x,shape =  List_GammaObj[[EventName]][[day]]$estimate["shape"],
scale = 1/(List_GammaObj[[EventName]][[day]]$estimate["rate"])),
from = 0, to = max(d_plot),add = T)
}
par(mfrow = c(length(EventType_ToFit),(WaveLen)),
oma = c(0,0,0,0), mar = c(3.1,4.1,2.1,1))
sapply(EventType[-3],function(x) (sapply((1:(WaveLen)),
function(y) overlayEventChart(x,y))))
}
######## Correlation Analysis ####################
{
Cor_List = lapply(EventType_ToFit, function(x)
cor(t(matrix(unlist(GetEventSeries(x)),nrow = WaveLen))))
names(Cor_List) = EventType_ToFit
}
}
###################################################################
#    Fit Model to Outliers Shock
###################################################################
{
List_EventDates$XtremeOutliers = sort(c(Date_Original[-1][tsoModel$times],
List_EventDates$Xtreme))
List_EventDatesLogic$XtremeOutliers =
apply(cbind(sapply(seq(-BackwardWaveLen,ForwardWaveLen),CreateIndicator,
Date_Original,List_EventDates$XtremeOutliers))
,1,function(y){ return (T%in%y)})
List_EventIdentifier$XtremeOutliers =
cbind(sapply(seq(-BackwardWaveLen,ForwardWaveLen),
CreateIndicator,Date_Original,
List_EventDates$XtremeOutliers))%*%(1:(WaveLen))
List_EventByIdentifier$XtremeOutliers = GetEventSeries("XtremeOutliers")
####### Estimate Uniform distribution on xtreme shocks parameters by MLE #####
{
List_UniformObj = eUniform(unlist(List_EventByIdentifier$XtremeOutliers)^2)
}
}
####### Simulation Initialization #############
{
NPaths = 10000
SimulationEndDate = preceding(as.Date("2017-12-31","%Y-%m-%d"),'QuantLib/UnitedStates/NYSE')
SimulationStartDate =adjust("UnitedStates/NYSE", max(Date_Original,1)+1)
NumOfDays = bizdays(SimulationStartDate, SimulationEndDate, 'QuantLib/UnitedStates/NYSE')+1
}
####### Define Future Event Dates #############
{
Date_Future = bizseq(SimulationStartDate,SimulationEndDate,'QuantLib/UnitedStates/NYSE')
Date_Original.Full = c(Date_Original,Date_Future)
####### Read in future dates #######
Data_FuturesDates = read.csv("FutureDates.csv",header = T)
List_FutureEventDates = lapply(EventType, function(x) {
as.Date(as.character(Data_FuturesDates$Date[Data_FuturesDates$Type==x]),"%m/%d/%Y")
})
names(List_FutureEventDates) = EventType
####### Consolidate future dates #######
List_EventDates.Full = lapply(EventType, function(x){
return(c(List_EventDates[[x]], List_FutureEventDates[[x]]))
})
names(List_EventDates.Full) = EventType
### Trim Date to make sure whole wave exists
WavelengthExistVector = function(stage,EventName)
{
return(sapply(List_EventDates.Full[[EventName]],function(x) return((x+stage)%in%Date_Original.Full[-1])))
}
List_ExistVector.Full = lapply(EventType,function(x){
1==apply(cbind(sapply(seq(-BackwardWaveLen,ForwardWaveLen),WavelengthExistVector,x)),1,prod)
})
names(List_ExistVector.Full) = EventType
List_EventDates.Full = lapply(EventType,function(x) List_EventDates.Full[[x]]=List_EventDates.Full[[x]][List_ExistVector.Full[[x]]==T])
names(List_EventDates.Full) = EventType
####### Define Future Event Indicator #############
List_EventDatesLogic.Full = lapply(EventType, function(x) {
apply(cbind(sapply(seq(-BackwardWaveLen,ForwardWaveLen),
CreateIndicator,Date_Original.Full,List_EventDates.Full[[x]]))
,1,function(y){ return (T%in%y)})
})
names(List_EventDatesLogic.Full) = EventType
AllEventsLogic.Full = apply(matrix(unlist(List_EventDatesLogic.Full),ncol = length(EventType)),1,
function(x){ return(T%in% x)})
####### Define Future Event Stage Identifier #############
List_EventIdentifier.Full = lapply(EventType, function(x){
return(cbind(sapply(seq(-BackwardWaveLen,ForwardWaveLen),
CreateIndicator,Date_Original.Full,List_EventDates.Full[[x]]))%*%(1:(WaveLen)))
})
names(List_EventIdentifier.Full) = EventType
List_EventIdentifier.Future = list()
List_EventIdentifier.Future = lapply(EventType, function(x){
List_EventIdentifier.Future[[x]] = List_EventIdentifier.Full[[x]][Date_Original.Full>=SimulationStartDate]
})
names(List_EventIdentifier.Future) = EventType
AllEventsLogic.Future = AllEventsLogic.Full[Date_Original.Full>=SimulationStartDate]
####### Define Event Count List #############
{
List_FutureEventCount = lapply(EventType, function(x){
as.numeric(table(List_EventIdentifier.Future[[x]]))[-1]
})
names(List_FutureEventCount) = EventType
}
}
####### Create Square Root Gamma Distribution (SRGM) #############
{
pSRGM = Vectorize(function(x,shape=2,rate=1,lower.tail = T){
if(x==0)
{
LowerTailProb = .5
}else
{
if(x<0)
{
LowerTailProb = (pgamma(x^2,shape = shape,rate = rate,lower.tail = F)*.5)
}else
{
LowerTailProb = (.5+pgamma(x^2,shape = shape,rate = rate)*.5)
}
}
if(lower.tail)
{
return(LowerTailProb)
}else
{
return(1-LowerTailProb)
}
})
#SquareRootGamma = AbscontDistribution(p = pSRGM)
dSRGM = function(x,shape = 2,rate = 1){
shape0 =shape
rate0 = rate
pSRGM = Vectorize(function(x,shape = shape0,rate=rate0,lower.tail = T){
if(x==0)
{
LowerTailProb = .5
}else
{
if(x<0)
{
LowerTailProb = (pgamma(x^2,shape = shape,rate = rate,lower.tail = F)*.5)
}else
{
LowerTailProb = (.5+pgamma(x^2,shape = shape,rate = rate)*.5)
}
}
if(lower.tail)
{
return(LowerTailProb)
}else
{
return(1-LowerTailProb)
}
})
SquareRootGamma = AbscontDistribution(p = pSRGM)
return(d(SquareRootGamma)(x))
}
qSRGM = function(p,shape = 2,rate = 1){
shape0 =shape
rate0 = rate
pSRGM = Vectorize(function(x,shape = shape0,rate=rate0,lower.tail = T){
if(x==0)
{
LowerTailProb = .5
}else
{
if(x<0)
{
LowerTailProb = (pgamma(x^2,shape = shape,rate = rate,lower.tail = F)*.5)
}else
{
LowerTailProb = (.5+pgamma(x^2,shape = shape,rate = rate)*.5)
}
}
if(lower.tail)
{
return(LowerTailProb)
}else
{
return(1-LowerTailProb)
}
})
SquareRootGamma = AbscontDistribution(p = pSRGM)
return(q(SquareRootGamma)(p))
}
}
####### Simulated Outlier Shocks #############
{
}
####### Simulated Event Shocks #############
{
resimulate = F
Read.ShockMatrix = function(futureDates, FilePath){
DataIn = read.csv(FilePath,header = F)
Date.Index = match(futureDates,as.Date(DataIn[,1],'1970-01-01'))
return(as.matrix(DataIn[,-1])[Date.Index,])
}
if(resimulate){
###### Define rMvdc.SRGM function ######
rMvdc.SRGM = function (n, mvdc){
dim <- mvdc@copula@dimension
u <- rCopula(n, mvdc@copula)
x = matrix(nrow = n,ncol = dim)
for (i in 1:dim) {
qfunc = Vectorize(function(u){
qfuncName = paste0("q",mvdc@margins[i])
qfuncEval = match.fun(qfuncName)
shape0 = mvdc@paramMargins[[i]]$shape
rate0 = mvdc@paramMargins[[i]]$rate
return(qfuncEval(u,shape =shape0,rate = rate0))
})
x[, i] <- qfunc(u[, i])
}
return(x)
}
Generate.ParaList = function(EventType){
resultList = list()
for(i in 1:WaveLen){
resultList[[i]]=list(shape=List_GammaObj[[EventType]][[i]]$estimate[1],
rate=List_GammaObj[[EventType]][[i]]$estimate[2])
}
return(resultList)
}
####### Simulate #######
SimulateShocks.Raw = function(EventName){
corrList = Cor_List[[EventName]][lower.tri(Cor_List[[EventName]])]
myCop <- normalCopula(param=corrList, dim = WaveLen, dispstr = "un")
myMvd <- mvdc(copula=myCop, margins=rep("SRGM",WaveLen),
paramMargins=Generate.ParaList(EventName))
return(rMvdc.SRGM(NPaths,myMvd))
}
SimulateShocks = function(EventName){
tryCatch({
SimulateShocks.Raw(EventName)
},
error=function(e) {
print(e)
stop(e)
})
}
simulate.Schedule = unlist(sapply(EventType_ToFit,function(x){
return(rep(x,max(List_FutureEventCount[[x]])))
}))
###### Parallel Simulations ######
List_SimulatedShocks.Raw = list()
List_SimulatedShocks = list()
no_cores <<- detectCores()-1
cl <<- makeCluster(no_cores)
cl <<- makeCluster(no_cores, outfile='')
# environment(x) <- .GlobalEnv
clusterExport(cl,ls(.GlobalEnv))
clusterEvalQ(cl, library(copula))
clusterEvalQ(cl, library(distr))
List_SimulatedShocks.Raw = parLapply(cl,simulate.Schedule,SimulateShocks)
stopCluster(cl)
List_SimulatedShocks = lapply(EventType_ToFit,function(x){
return(lapply(which(simulate.Schedule ==x),function(i){
return(List_SimulatedShocks.Raw[[i]])}))
})
names(List_SimulatedShocks) = EventType_ToFit
rm(List_SimulatedShocks.Raw)
####### Reconstruct Simulations (Combine with Outlier Shocks) #######
List_SimulatedShocks.Reconstruct = lapply(EventType_ToFit, function(x){
tempM = matrix()
tempM = matrix(unlist(List_SimulatedShocks[[x]]),nrow  = NPaths)
return(lapply(1:WaveLen,function(i){
t(tempM[,WaveLen*(0:(max(List_FutureEventCount[[x]])-1))+i])
}))
})
names(List_SimulatedShocks.Reconstruct) = EventType_ToFit
####### Construct simulated shock matrix #######
ShockMatrix = matrix(0,nrow = NumOfDays, ncol = NPaths)
for(x in EventType){
for(i in 1:WaveLen){
ShockMatrix[List_EventIdentifier.Future[[x]]==i,] = List_SimulatedShocks.Reconstruct[[x]][[i]]
}
}
}else{
ShockMatrix = Read.ShockMatrix(Date_Future,'ShockMatrix.csv')
}
}
####### Output simulated shock matrix #######
{
# write.table(cbind(Date_Future,ShockMatrix),"ShockMatrix.csv",sep = ',',row.names = F,col.names = F)
}
####### Simulated ExEvent Process #############
{
garchModel = ugarchsim(maxGarchFit,n.sim = NumOfDays,m.sim = NPaths,
startMethod =  "sample")
}
######### Consolidate simulation results ##########
Fitted.Combined = fitted(garchModel)
Fitted.Combined[AllEventsLogic.Future, ]=0
Fitted.Combined = Fitted.Combined +  ShockMatrix
######### Declare Functions ##########
Calculate_Fitted.Expiry.Prices = function(ExpiryDate)
{
LastClose = Prices_Original[Date_Original==max(Date_Original)]
MaturityLength = bizdays(SimulationStartDate, ExpiryDate, 'QuantLib/UnitedStates/NYSE')+1
Fitted.Expiry.Returns = apply(Fitted.Combined,2,function(x){
prod(exp(head(x,MaturityLength)))
})
return(LastClose*Fitted.Expiry.Returns)
}
aa = Calculate_Fitted.Expiry.Prices(as.Date('2017-05-12','yyyy-MM-dd'))
ExpiryDate = as.Date('2017-05-12','yyyy-MM-dd')
LastClose = Prices_Original[Date_Original==max(Date_Original)]
MaturityLength = bizdays(SimulationStartDate, ExpiryDate, 'QuantLib/UnitedStates/NYSE')+1
Fitted.Expiry.Returns = apply(Fitted.Combined,2,function(x){
prod(exp(head(x,MaturityLength)))
})
MaturityLength
SimulationStartDate
ExpiryDate
ExpiryDate = as.Date("2017-05-12","%Y-%m-%d")
LastClose = Prices_Original[Date_Original==max(Date_Original)]
MaturityLength = bizdays(SimulationStartDate, ExpiryDate, 'QuantLib/UnitedStates/NYSE')+1
Fitted.Expiry.Returns = apply(Fitted.Combined,2,function(x){
prod(exp(head(x,MaturityLength)))
})
Fitted.Expiry.Prices = Calculate_Fitted.Expiry.Prices(ExpiryDate)
Cond.Loss(45)
payoff = function(ST,K,Premium,Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
return(Premium - max(direction*(K-ST),0)*100)
}
Probability.OTM = function(K, Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
return(sum(direction*(Fitted.Expiry.Prices-K) > 0)/NPaths)
}
Cond.Loss = function(K, Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
return(direction*(K-Fitted.Expiry.Prices[(direction*(K-Fitted.Expiry.Prices))>0]))
}
ExReturn = function(K,Premium,Right = 'PUT'){
return(mean(sapply(Fitted.Expiry.Prices,payoff,K,Premium,Right)))
}
SDReturn = function(K,Premium,Right = 'PUT'){
return(sd(sapply(Fitted.Expiry.Prices,payoff,K,Premium,Right)))
}
Cond.Loss(45)
K = 45
Right = 'PUT'
direction = 2*(Right == 'PUT')-1
direction
Cond.Loss = function(K, Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
return (mean(direction*(K-Fitted.Expiry.Prices[(direction*(K-Fitted.Expiry.Prices))>0])))
}
Cond.Loss(45)
aa = (direction*(K-Fitted.Expiry.Prices[(direction*(K-Fitted.Expiry.Prices))>0]))
str(aa)
head(aa)
head(Fitted.Expiry.Prices)
head(Fitted.Expiry.Prices[(direction*(K-Fitted.Expiry.Prices))>0])
range(Fitted.Expiry.Prices)
Cond.Loss = function(K, Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
conLoss = mean(direction*(K-Fitted.Expiry.Prices[(direction*(K-Fitted.Expiry.Prices))>0]))
if(is.na(conLoss))
{
conLoss = 0
}
return (conLoss)
}
Cond.Loss(45)
Cond.Loss(55)
