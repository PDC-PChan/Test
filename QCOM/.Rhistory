Earnings_1= 1:100
1=T
1==T
0=T
0==T
0==F
apply?
?apply
?lapply
?apply
a = c(1,2)
b = c(1,1,2,2)
match(a,b)
aa = as.Date("2017-03-19","%Y-%m-%d")
aa
as.numeric(aa)
FilePath = 'C:/Users/Samuel/Documents/Book1.csv'
DataIn = read.csv(FilePath,header = F)
ShockMatrix.Raw = as.matrix(DataIn[,-1])
ShockMatrix.Raw
as.Date(DataIn[,1])
as.Date(DataIn[,1],'1970-1-1')
?as.Date
install.packages("libsvm")
load("C:/Users/Samuel/Downloads/.RData")
rm(list=ls())
Right = 'Put'
direction = 2*(Right == 'Put')-1
direction
source('~/Visual Studio 2013/Projects/ConsoleApplication5/R Codes/R_RequireFiles.R')
###################################################################
#    Prepare Libraries
###################################################################
{
# install.packages('Rcpp')
# install.packages('multicool')
# install.packages('rugarch')
# install.packages('coda')
# install.packages('stochvol')
# install.packages('shiny')
# install.packages('tsoutliers')
# install.packages('pracma')
# install.packages('VGAM')
# install.packages('MASS')
# install.packages('ExtDist')
# install.packages('survival')
# install.packages('Hmisc')
# install.packages('copula')
# install.packages('distr')
# {
#  install.packages('drat')
#  drat::addRepo('ghrr')
#  install.packages('RQuantLib', type='binary')
# }
# install.packages('bizdays')
#
# install.packages('moments')
# install.packages('snow')
# install.packages('parallel')
# install.packages('foreach')
# install.packages('doParallel')
# install.packages('xts')
# install.packages('rmgarch')
require('Rcpp')
require('shiny')
require('parallel')
require('multicool')
require('rugarch')
require('reshape2')
require('coda')
require('stochvol')
require('tsoutliers')
require('pracma')
require('VGAM')
require('MASS')
require('ExtDist')
require('survival')
require('Hmisc')
require('copula')
require('distr')
require('RQuantLib')
require('bizdays')
require('moments')
require('parallel')
require('foreach')
require('doParallel')
require('xts')
require('rmgarch')
require('DEoptim')
Parent.WD = 'C:/Users/Samuel/Documents/dfkjdf/'
asset.1 = list(symbol = 'CPB',Expiry = as.Date('2017-07-21'),Strike = 52.5,Right = 'PUT',Premium = 0.216666666666667, Margin = 5066.47,ER = 0.0311982883988784)
asset.2 = list(symbol = 'DIS',Expiry = as.Date('2017-07-14'),Strike = 98,Right = 'PUT',Premium = 0.765, Margin = 9604.49,ER = 0.0593265339123075)
asset.3 = list(symbol = 'DIS',Expiry = as.Date('2017-07-14'),Strike = 98.5,Right = 'PUT',Premium = 0.575, Margin = 9846,ER = 0.0422555982591741)
asset.4 = list(symbol = 'JNJ',Expiry = as.Date('2017-07-14'),Strike = 116,Right = 'PUT',Premium = 0.225, Margin = 10282.67,ER = 0.0162311036069484)
asset.5 = list(symbol = 'JNJ',Expiry = as.Date('2017-07-21'),Strike = 115,Right = 'PUT',Premium = 0.223333333333333, Margin = 9552.06,ER = 0.0166653297695537)
asset.6 = list(symbol = 'MCD',Expiry = as.Date('2017-08-18'),Strike = 135,Right = 'PUT',Premium = 0.5, Margin = 10865.41,ER = 0.0329401801778536)
asset.7 = list(symbol = 'MCD',Expiry = as.Date('2017-08-18'),Strike = 130,Right = 'PUT',Premium = 0.3, Margin = 10335.38,ER = 0.022082354879811)
asset.8 = list(symbol = 'MMM',Expiry = as.Date('2017-07-14'),Strike = 177.5,Right = 'PUT',Premium = 0.22, Margin = 13945.14,ER = 0.0119344714422737)
asset.9 = list(symbol = 'NKE',Expiry = as.Date('2017-06-23'),Strike = 45,Right = 'PUT',Premium = 0.0633333333333333, Margin = 3516.21,ER = 0.013959985498273)
asset.10 = list(symbol = 'ORCL',Expiry = as.Date('2017-07-14'),Strike = 38.5,Right = 'PUT',Premium = 0.1, Margin = 3044.99,ER = 0.0235697449072202)
asset.11 = list(symbol = 'QCOM',Expiry = as.Date('2017-07-14'),Strike = 51,Right = 'PUT',Premium = 0.31, Margin = 4053.14,ER = 0.0510594786656742)
assets = lapply(1:11,function(x) return(get(paste0('asset.',x))))
SymbolList = unique(sapply(assets,function(x) return(x[['symbol']])))
}
###################################################################
#    Set Parameters
###################################################################
{
BackwardWaveLen  = 0
ForwardWaveLen  = 1
WaveLen = BackwardWaveLen + ForwardWaveLen + 1
}
###################################################################
#    Prepare Data Sets
###################################################################
{
Get.Clean.DatePrice = function(wd) {
####### Read in data  #############
setwd(wd)
Data_Prices = read.csv('Prices.csv', T)
Data_Dates = read.csv('Dates.csv', T)
Prices_Original = Data_Prices$Close
N = length(Prices_Original)
EventType = as.vector(c('Earnings', 'FOMC', 'Xtreme'), mode = 'list')
####### Define Dates and Event Dates #############
Date_Original = as.Date(as.character(Data_Prices$Date), '%Y-%m-%d')
Prices_Original = Prices_Original[order(Date_Original)]
Date_Original = sort(Date_Original)
List_EventDates = lapply(EventType, function(x) {
as.Date(as.character(Data_Dates$Date[Data_Dates$Type == x]), '%m/%d/%Y')
})
names(List_EventDates) = EventType
load_quantlib_calendars('UnitedStates/NYSE',
from = min(Date_Original) - 50,
to = '2021-12-29')
### Trim Date to make sure whole wave exists
WavelengthExistVector = function(stage, EventName)
{
return(sapply(List_EventDates[[EventName]], function(x)
return(
offset(x, stage, 'QuantLib/UnitedStates/NYSE') %in% Date_Original[-1]
)))
}
List_ExistVector = lapply(EventType, function(x) {
1 == apply(cbind(sapply(
seq(-BackwardWaveLen, ForwardWaveLen),
WavelengthExistVector,
x
)), 1, prod)
})
names(List_ExistVector) = EventType
List_EventDates = lapply(EventType, function(x)
List_EventDates[[x]] = List_EventDates[[x]][List_ExistVector[[x]] == T])
names(List_EventDates) = EventType
####### Define Event Indicator #############
CreateIndicator = function(WaveSize, GrandDates, TargetDates)
{
ResultIndicator = rep(F, length(GrandDates))
ResultIndicator[pmax(match(TargetDates, GrandDates) + WaveSize, 1)] = T
return(ResultIndicator)
}
List_EventDatesLogic = lapply(EventType, function(x) {
apply(cbind(
sapply(
seq(-BackwardWaveLen, ForwardWaveLen),
CreateIndicator,
Date_Original,
List_EventDates[[x]]
)
)
, 1, function(y) {
return (T %in% y)
})
})
names(List_EventDatesLogic) = EventType
AllEventsLogic = apply(matrix(unlist(List_EventDatesLogic), ncol = length(EventType)), 1,
function(x) {
return(T %in% x)
})
####### Define Event Stage Identifier #############
List_EventIdentifier = lapply(EventType, function(x) {
return(cbind(
sapply(
seq(-BackwardWaveLen, ForwardWaveLen),
CreateIndicator,
Date_Original,
List_EventDates[[x]]
)
) %*% (1:(WaveLen)))
})
names(List_EventIdentifier) = EventType
##### 1. Return_Original ######
Return_Original = log(Prices_Original[-1] / Prices_Original[-N])
##### 2. Return_ExEvent ######
Return_ExEvent = Return_Original
Mean_ExEvent = mean(Return_ExEvent[AllEventsLogic[-1] == F])
Sd_ExEvent = sd(Return_ExEvent[AllEventsLogic[-1] == F])
Return_ExEvent[AllEventsLogic[-1] == T] = rnorm(length(which(AllEventsLogic[-1] ==
T)), Mean_ExEvent, Sd_ExEvent)
return(list(Date = Date_Original[-1], Return = as.ts(Return_ExEvent)))
}
DatePrices = lapply(paste0(Parent.WD, SymbolList), Get.Clean.DatePrice)
names(DatePrices) = SymbolList
########### Consolidate Date ###########
Date.Raw = unique(as.numeric(unlist(sapply(SymbolList, function(x) {
return(DatePrices[[x]]$Date)
}))))
Date.Final = as.Date(Date.Raw[order(Date.Raw)])
########### Consolidate Prices ###########
Return.Final = lapply(lapply(SymbolList, function(x) {
return(DatePrices[[x]]$Return[match(Date.Final, DatePrices[[x]]$Date)])
}), na.locf)
Final.DF = data.frame(matrix(
unlist(Return.Final),
byrow = F,
ncol = length(SymbolList)
))
names(Final.DF) = SymbolList
Final.DF$Date = Date.Final
}
###################################################################
#    Fit Multivate-GARCH Model to ExEvent Returns
###################################################################
{
noise = c('norm',
'snorm',
'std',
'sstd',
'ged',
'sged',
'nig',
'ghyp',
'jsu')
ARMA.Order = c(2, 2)
GetMaxLLSpec = function(symbol) {
Ret_ExEvent = as.ts(Final.DF[symbol])
# Remove all additive outliers
tsoModel = tso(
y = Ret_ExEvent,
types = c('AO'),
tsmethod = 'auto.arima',
args.tsmodel = list(model = 'local-level')
)
# Fit Garch with noise type of Max LL
GarchLL = function(noiseType, inputData)
{
spec = ugarchspec(
mean.model = list(armaOrder = ARMA.Order, include.mean = TRUE),
variance.model = list(model = 'sGARCH'),
distribution.model = noiseType
)
fit = ugarchfit(spec, data = inputData, solver = 'hybrid')
return(likelihood(fit))
}
GarchLL  = sapply(noise, GarchLL, tsoModel$yadj)
maxGarchLLIndex = which(GarchLL == max(GarchLL))
maxGarchSpec = ugarchspec(
mean.model = list(armaOrder = ARMA.Order, include.mean = TRUE),
variance.model = list(model = 'sGARCH'),
distribution.model = noise[maxGarchLLIndex]
)
maxGarchFit = ugarchfit(maxGarchSpec, data = tsoModel$yadj, solver = 'hybrid')
return(list(Fit = maxGarchFit, Spec = maxGarchSpec))
# return( list(Spec =maxGarchSpec ))
}
tso.Remove = function(symbol) {
Ret_ExEvent = as.ts(Final.DF[symbol])
tsoModel = tso(
y = Ret_ExEvent,
types = c('AO'),
tsmethod = 'auto.arima',
args.tsmodel = list(model = 'local-level')
)
return(tsoModel$yadj)
}
Final.DF.oF = data.frame(matrix(
unlist(lapply(SymbolList, tso.Remove)),
byrow = F,
ncol = length(SymbolList)
))
names(Final.DF.oF) = SymbolList
Final.DF.oF$Date = Date.Final
###### Parallel Garch Spec Generation ######
no_cores <<- detectCores() - 1
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, ls(.GlobalEnv))
dummy = clusterEvalQ(cl, library(rugarch))
dummy = clusterEvalQ(cl, library(tsoutliers))
SpecAndFit = parLapply(cl, SymbolList, GetMaxLLSpec)
stopCluster(cl)
FitList = lapply(SpecAndFit, function(x)
return(x$Fit))
SpecList = lapply(SpecAndFit, function(x)
return(x$Spec))
Specs.GARCHs = multispec(SpecList)
###### Fit the mgarch model ######
Specs.DCC = dccspec(
Specs.GARCHs,
VAR = F,
dccOrder = c(1, 1),
model = 'DCC',
distribution = 'mvlaplace'
)
Final.xts = as.xts(Final.DF.oF[, -(1 + length(SymbolList))], order.by =
Final.DF.oF[, length(SymbolList) + 1])
cl <<- makeCluster(no_cores, outfile = '')
clusterExport(cl, ls(.GlobalEnv))
DCC.Model = dccfit(
spec =  Specs.DCC,
data = Final.xts,
solver = c('hybrid', 'solnp'),
cluster = cl
)
stopCluster(cl)
}
###################################################################
#    Generate New Time Series
###################################################################
{
####### Simulation Initialization #############
{
NPaths = 10000
SimulationEndDate = preceding(as.Date("2017-12-31", "%Y-%m-%d"),
'QuantLib/UnitedStates/NYSE')
SimulationStartDate = adjust("UnitedStates/NYSE", max(Final.DF.oF$Date, 1) +
1)
NumOfDays = bizdays(SimulationStartDate,
SimulationEndDate,
'QuantLib/UnitedStates/NYSE') + 1
Date_Future = bizseq(SimulationStartDate,SimulationEndDate,'QuantLib/UnitedStates/NYSE')
}
####### Read in Shock Matricess  #############
{
Read.ShockMatrix = function(futureDates, FilePath){
DataIn = read.csv(FilePath,header = F)
Date.Index = match(futureDates,as.Date(DataIn[,1],'1970-01-01'))
return(as.matrix(DataIn[,-1])[Date.Index,])
}
List.ShockMatrices = lapply(paste0(Parent.WD, SymbolList, '/ShockMatrix.csv'), function(fileAdd) {
return(Read.ShockMatrix(Date_Future, fileAdd))
})
names(List.ShockMatrices) = SymbolList
}
####### Simulate m-GARCH process  #############
mGARCHsim = dccsim(
DCC.Model,
n.sim = NumOfDays,
m.sim = NPaths,
startMethod =  'sample' ,
rseed = 0
)
Simmed.Path = mGARCHsim@msim$simX
Simmed.Path.rbind = do.call("rbind", Simmed.Path)
Simmed.Path.List = lapply((1:length(SymbolList)), function(i) {
return(matrix(Simmed.Path.rbind[, i], byrow = F, ncol = NPaths))
})
names(Simmed.Path.List) = SymbolList
############### combined process with Shocks #############
for(i in (1:length(SymbolList))){
symbol = SymbolList[i]
Simmed.Path.List[[symbol]][List.ShockMatrices[[symbol]][,1]!=0,] = 0
Simmed.Path.List[[symbol]] = Simmed.Path.List[[symbol]] + List.ShockMatrices[[symbol]]
}
rm(mGARCHsim)
rm(Simmed.Path)
rm(List.ShockMatrices)
gc()
}
###################################################################
#       Usefull function for calculation
###################################################################
{
Calculate_Fitted.Expiry.Prices = function(symbol,ExpiryDate)
{
####### Read in data  #############
setwd(paste0(Parent.WD,'/',symbol ))
Data_Prices = read.csv('Prices.csv', T)
LastClose = Data_Prices$Close[as.Date(Data_Prices$Date,'%Y-%m-%d') == max(Final.DF$Date)]
MaturityLength = bizdays(SimulationStartDate, ExpiryDate, 'QuantLib/UnitedStates/NYSE')+1
Fitted.Expiry.Returns = apply(Simmed.Path.List[[symbol]],2,function(x){
prod(exp(head(x,MaturityLength)))
})
return(LastClose*Fitted.Expiry.Returns)
}
payoff = function(ST,K,Premium,Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
return(Premium - max(direction*(K-ST),0))
}
Probability.OTM = function(K,Sim.Prices, Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
return(sum(direction*(Sim.Prices-K) > 0)/NPaths)
}
Cond.Loss = function(K,Sim.Prices, Right = 'PUT'){
direction = 2*(Right == 'PUT')-1
conLoss = mean(direction*(K-Sim.Prices[(direction*(K-Sim.Prices))>0]))
if(is.na(conLoss)) conLoss = 0
return(conLoss)
}
ExReturn = function(K,Sim.Prices,Premium,Right = 'PUT'){
return(mean(sapply(Sim.Prices,payoff,K,Premium,Right)))
}
SDReturn = function(K,Sim.Prices,Premium,Right = 'PUT'){
return(sd(sapply(Sim.Prices,payoff,K,Premium,Right)))
}
}
###################################################################
#       Calculate correlation between assets
###################################################################
{
GetCov = function(asset.A, asset.B) {
assetss = list(asset.A, asset.B)
Sim.Prices = lapply(1:2, function(x) {
return(Calculate_Fitted.Expiry.Prices(assetss[[x]]$symbol, assetss[[x]]$Expiry))
})
Returns = lapply(1:2, function(x) {
return(
sapply(
Sim.Prices[[x]],
payoff,
assetss[[x]]$Strike,
assetss[[x]]$Premium,
assetss[[x]]$Right
) / assetss[[x]]$Margin * 780
)
})
return(max(2^-20,cov(Returns[[1]],Returns[[2]])))
}
Cov.Matrix = do.call('rbind',lapply(assets,function(x) return(sapply(assets,GetCov,x))))
}
{
ExcessMargin = 113000
Sharpe = function(N,assets,CovMatrix){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns) #/sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
Return.Function = function(N,assets){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns)
}
SD.Function = function(N,assets,CovMatrix){
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
ReqMargin = function(N,assets){
return(N%*%(sapply(assets,function(x) x[['Margin']])))
}
Split.n.Get = function(x,n,i){
return(split(x, ceiling(seq_along(x)/n))[[j]])
}
Sharpe.Modified = function(N)
{
##### Set up restrictions #####
# If exceed margin
if(ReqMargin(N,assets)>ExcessMargin){
return (0)
}
# If any negative
if(T%in%(N<0)){
return(0)
}
# If any negative
if(sum(N)==0){
return(0)
}
##### Return functions #####
return(-Sharpe(N,assets,Cov.Matrix))
}
Return.Modified = function(N)
{
##### Set up restrictions #####
# If exceed margin
if(ReqMargin(N,assets)>ExcessMargin){
return (0)
}
# If any negative
if(T%in%(N<0)){
return(0)
}
# If any negative
if(sum(N)==0){
return(0)
}
##### Return functions #####
return(-Return.Function(N,assets))
}
Max.Holding = sapply(1:length(assets),function(x) return(ExcessMargin%/%assets[[x]]$Margin))
Model.MaxSharpe = DEoptim(fn=Sharpe.Modified,lower=rep(0,length(assets)),upper = rep(3,length(assets)),
control = DEoptim.control(NP = 200,itermax = 2000, trace = T,p = .1),fnMap = round)
Model.MaxReturn = DEoptim(fn=Return.Modified,lower=rep(0,length(assets)),upper = rep(3,length(assets)),
control = DEoptim.control(NP = 200,itermax = 2000, trace = T,p = .1),fnMap = round)
}
Model.MaxSharpe$optim$bestval
Model.MaxReturn$optim$bestval
Sharpe = function(N,assets,CovMatrix){
Returns = sapply(assets,function(x) x[['ER']])
Mar.Matrix = diag(sapply(assets,function(x) x[['Margin']]))
return(N%*%Mar.Matrix%*%Returns/sqrt(N%*%Mar.Matrix%*%CovMatrix%*%Mar.Matrix%*%N))
}
Model.MaxSharpe = DEoptim(fn=Sharpe.Modified,lower=rep(0,length(assets)),upper = rep(3,length(assets)),
control = DEoptim.control(NP = 200,itermax = 2000, trace = T,p = .1),fnMap = round)
Sharpe(Model.MaxReturn$optim$bestmem,assets,Cov.Matrix)
Return.Function(Model.MaxSharpe$optim$bestmem,assets)*(ExcessMargin%/%ReqMargin(Model.MaxSharpe$optim$bestmem,assets))
Model.MaxReturn$optim$bestval
ReqMargin(Model.MaxSharpe$optim$bestmem,assets)
Sharpe(Model.MaxReturn$optim$bestmem,assets,Cov.Matrix)
Model.MaxReturn$optim$bestval
Sharpe(Model.MaxReturn$optim$bestmem,assets,Cov.Matrix)
Return.Function(Model.MaxSharpe$optim$bestmem,assets)*(ExcessMargin%/%ReqMargin(Model.MaxSharpe$optim$bestmem,assets))
Model.MaxSharpe$optim$bestval
Model.MaxReturn$optim$bestmem
